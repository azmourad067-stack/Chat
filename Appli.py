def _scrape_partants_page(self, soup):
        """Scrape une page 'partants-pmu' Geny"""
        st.info("ðŸ“„ DÃ©tection: Page Partants PMU")
        
        horses_data = []
        
        # MÃ©thode 1: Chercher le tableau principal
        table = soup.find('table') or soup.find('tbody')
        
        if table:
            st.info("âœ… Tableau dÃ©tectÃ©, extraction en cours...")
            rows = table.find_all('tr')
            
            for row in rows:
                # Chercher les cellules
                cells = row.find_all(['td', 'th'])
                if len(cells) < 3:  # Ignorer les lignes d'en-tÃªte
                    continue
                
                horse_data = self._extract_from_table_row(row, cells)
                if horse_data and horse_data.get('Nom'):
                    horses_data.append(horse_data)
                    st.success(f"âœ“ Cheval extrait: {horse_data['Nom']}")
        
        # MÃ©thode 2: Fallback vers divs/spans
        if not horses_data:
            st.info("ðŸ“¦ Tentative extraction via divs...")
            horse_elements = soup.find_all('tr') or soup.find_all('div', recursive=True)
            
            for element in horse_elements[:20]:
                horse_data = self._extract_horse_data_from_element(element)
                if horse_data and horse_data['Nom'] != "CHEVAL INCONNU":
                    horses_data.append(horse_data)
        
        if horses_data:
            st.success(f"ðŸŽ¯ {len(horses_data)} chevaux extraits avec succÃ¨s")
            return pd.DataFrame(horses_data)
        else:
            st.warning("âš ï¸ Extraction standard Ã©chouÃ©e, passage en mode analyse gÃ©nÃ©rique")
            return self._scrape_generic_page(soup)
