import streamlit as st
import pandas as pd
import numpy as np
import requests
from bs4 import BeautifulSoup
import re
import json
from datetime import datetime
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# ML & Deep Learning
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor
from sklearn.linear_model import Ridge, Lasso, ElasticNet, LogisticRegression
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.model_selection import cross_val_score, KFold, train_test_split
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error
from sklearn.neural_network import MLPRegressor
import warnings
warnings.filterwarnings('ignore')

st.set_page_config(page_title="üèá Analyseur Hippique Pro ML v2", page_icon="üèá", layout="wide")

st.markdown("""
<style>
    .main-header {font-size: 2.8rem; color: #1e3a8a; text-align: center; margin-bottom: 1.5rem;}
    .metric-card {background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 1rem; 
                  border-radius: 10px; color: white; text-align: center; margin: 0.5rem 0;}
    .prediction-box {border-left: 4px solid #f59e0b; padding: 0.8rem; background: #fffbeb; 
                     margin: 0.8rem 0; border-radius: 6px;}
    .confidence-high {color: #10b981; font-weight: bold;}
    .confidence-medium {color: #f59e0b; font-weight: bold;}
    .confidence-low {color: #ef4444; font-weight: bold;}
    .feature-importance {background: #f0f9ff; padding: 1rem; border-radius: 8px; margin: 1rem 0;}
</style>
""", unsafe_allow_html=True)

# ============================================================================
# CONFIGURATION & CONSTANTES
# ============================================================================

RACE_CONFIGS = {
    "PLAT": {"weight_importance": 0.25, "draw_advantage": [1, 2, 3, 4], "age_optimal": (4, 6)},
    "ATTELE_AUTO": {"weight_importance": 0.05, "draw_advantage": [4, 5, 6], "age_optimal": (5, 8)},
    "ATTELE_VOLTE": {"weight_importance": 0.05, "draw_advantage": [], "age_optimal": (5, 8)},
    "OBSTACLE": {"weight_importance": 0.20, "draw_advantage": [], "age_optimal": (6, 10)}
}

# ============================================================================
# EXTRACTEUR DE FEATURES AVANC√â
# ============================================================================

class AdvancedFeatureExtractor:
    """Extraction compl√®te des features √† partir des donn√©es brutes"""
    
    @staticmethod
    def extract_music_stats(music_str):
        """Analyse d√©taill√©e de la musique (historique de performances)"""
        if pd.isna(music_str) or str(music_str).strip() == '':
            return {
                'total_races': 0, 'wins': 0, 'places_1_3': 0, 'places_1_5': 0,
                'win_rate': 0, 'place_rate': 0, 'top5_rate': 0,
                'recent_form_3': 0, 'recent_form_5': 0, 'recent_form_10': 0,
                'consistency_score': 0, 'best_position': 20, 'worst_position': 20,
                'avg_position': 10, 'median_position': 10, 'position_std': 10,
                'improvement_trend': 0, 'consecutive_wins': 0, 'consecutive_places': 0,
                'dns_dnf_rate': 0
            }
        
        music = str(music_str).upper()
        
        # Extraction des positions num√©riques
        positions = []
        dns_dnf = 0
        
        for char in music:
            if char.isdigit() and char != '0':
                positions.append(int(char))
            elif char in ['A', 'T', 'D']:  # Abandon, Tomb√©, Disqualifi√©
                dns_dnf += 1
        
        if not positions:
            positions = [20]  # Position par d√©faut si aucune donn√©e
        
        total = len(positions) + dns_dnf
        wins = positions.count(1)
        places_1_3 = sum(1 for p in positions if p <= 3)
        places_1_5 = sum(1 for p in positions if p <= 5)
        
        # Forme r√©cente pond√©r√©e (plus de poids aux courses r√©centes)
        def weighted_form(positions_list, n):
            recent = positions_list[:n]
            if not recent:
                return 0
            weights = np.linspace(1, 0.5, len(recent))
            scores = [1/p for p in recent]
            return np.average(scores, weights=weights)
        
        recent_form_3 = weighted_form(positions, 3)
        recent_form_5 = weighted_form(positions, 5)
        recent_form_10 = weighted_form(positions, 10)
        
        # Tendance d'am√©lioration (r√©gression lin√©aire sur les positions)
        if len(positions) >= 3:
            x = np.arange(len(positions))
            slope = np.polyfit(x, positions, 1)[0]
            improvement_trend = -slope  # N√©gatif = am√©lioration
        else:
            improvement_trend = 0
        
        # S√©ries de victoires/places cons√©cutives
        consecutive_wins = 0
        consecutive_places = 0
        for p in positions:
            if p == 1:
                consecutive_wins += 1
            else:
                break
        for p in positions:
            if p <= 3:
                consecutive_places += 1
            else:
                break
        
        # Consistance (inverse de l'√©cart-type)
        consistency = 1 / (np.std(positions) + 1) if len(positions) > 1 else 0
        
        return {
            'total_races': total,
            'wins': wins,
            'places_1_3': places_1_3,
            'places_1_5': places_1_5,
            'win_rate': wins / total if total > 0 else 0,
            'place_rate': places_1_3 / total if total > 0 else 0,
            'top5_rate': places_1_5 / total if total > 0 else 0,
            'recent_form_3': recent_form_3,
            'recent_form_5': recent_form_5,
            'recent_form_10': recent_form_10,
            'consistency_score': consistency,
            'best_position': min(positions) if positions else 20,
            'worst_position': max(positions) if positions else 20,
            'avg_position': np.mean(positions) if positions else 10,
            'median_position': np.median(positions) if positions else 10,
            'position_std': np.std(positions) if len(positions) > 1 else 10,
            'improvement_trend': improvement_trend,
            'consecutive_wins': consecutive_wins,
            'consecutive_places': consecutive_places,
            'dns_dnf_rate': dns_dnf / total if total > 0 else 0
        }
    
    @staticmethod
    def extract_age_sex_features(age_sex_str):
        """Extraction √¢ge et sexe avec features d√©riv√©es"""
        if pd.isna(age_sex_str):
            return {'age': 5, 'is_male': 0, 'is_female': 0, 'is_gelding': 0, 'age_category': 'mature'}
        
        age_sex = str(age_sex_str).upper()
        age_match = re.search(r'(\d+)', age_sex)
        age = int(age_match.group(1)) if age_match else 5
        
        is_male = 1 if 'H' in age_sex or 'M' in age_sex else 0
        is_female = 1 if 'F' in age_sex or 'J' in age_sex else 0
        is_gelding = 1 if 'H' in age_sex else 0
        
        if age <= 3:
            age_category = 'young'
        elif age <= 6:
            age_category = 'mature'
        else:
            age_category = 'veteran'
        
        return {
            'age': age,
            'is_male': is_male,
            'is_female': is_female,
            'is_gelding': is_gelding,
            'age_category': age_category
        }
    
    @staticmethod
    def create_comprehensive_features(df, race_type="PLAT"):
        """Cr√©ation de l'ensemble complet des features pour ML"""
        features = pd.DataFrame(index=df.index)
        config = RACE_CONFIGS.get(race_type, RACE_CONFIGS["PLAT"])
        
        # === FEATURES DE COTE (8 features) ===
        features['odds'] = df['odds_numeric']
        features['odds_inv'] = 1 / (df['odds_numeric'] + 0.1)
        features['log_odds'] = np.log1p(df['odds_numeric'])
        features['sqrt_odds'] = np.sqrt(df['odds_numeric'])
        features['odds_squared'] = df['odds_numeric'] ** 2
        features['odds_rank'] = df['odds_numeric'].rank()
        features['odds_percentile'] = df['odds_numeric'].rank(pct=True)
        features['odds_zscore'] = (df['odds_numeric'] - df['odds_numeric'].mean()) / (df['odds_numeric'].std() + 1e-6)
        
        # === FEATURES DE POSITION/NUM√âRO (6 features) ===
        features['draw'] = df['draw_numeric']
        features['draw_normalized'] = df['draw_numeric'] / (df['draw_numeric'].max() + 1)
        features['draw_rank'] = df['draw_numeric'].rank()
        
        optimal_draws = config['draw_advantage']
        features['is_optimal_draw'] = df['draw_numeric'].apply(lambda x: 1 if x in optimal_draws else 0)
        features['draw_distance_optimal'] = df['draw_numeric'].apply(
            lambda x: min([abs(x - opt) for opt in optimal_draws]) if optimal_draws else 0
        )
        features['draw_advantage_score'] = features['is_optimal_draw'] * (1 - features['draw_normalized'])
        
        # === FEATURES DE POIDS (8 features) ===
        features['weight'] = df['weight_kg']
        features['weight_normalized'] = (df['weight_kg'] - df['weight_kg'].mean()) / (df['weight_kg'].std() + 1e-6)
        features['weight_rank'] = df['weight_kg'].rank()
        features['weight_percentile'] = df['weight_kg'].rank(pct=True)
        features['weight_advantage'] = (df['weight_kg'].max() - df['weight_kg']) * config['weight_importance']
        features['weight_zscore'] = (df['weight_kg'] - df['weight_kg'].mean()) / (df['weight_kg'].std() + 1e-6)
        features['is_light_weight'] = (df['weight_kg'] < df['weight_kg'].quantile(0.25)).astype(int)
        features['is_heavy_weight'] = (df['weight_kg'] > df['weight_kg'].quantile(0.75)).astype(int)
        
        # === FEATURES DE MUSIQUE (20 features) ===
        if 'Musique' in df.columns:
            music_stats = df['Musique'].apply(AdvancedFeatureExtractor.extract_music_stats)
            for key in music_stats.iloc[0].keys():
                features[f'music_{key}'] = [m[key] for m in music_stats]
        else:
            default_music = AdvancedFeatureExtractor.extract_music_stats('')
            for key in default_music.keys():
                features[f'music_{key}'] = default_music[key]
        
        # === FEATURES D'√ÇGE ET SEXE (5 features + cat√©gorielles) ===
        if '√Çge/Sexe' in df.columns:
            age_sex_stats = df['√Çge/Sexe'].apply(AdvancedFeatureExtractor.extract_age_sex_features)
            for key in ['age', 'is_male', 'is_female', 'is_gelding']:
                features[key] = [m[key] for m in age_sex_stats]
            
            features['age_squared'] = features['age'] ** 2
            features['age_optimal'] = features['age'].apply(
                lambda x: 1 if config['age_optimal'][0] <= x <= config['age_optimal'][1] else 0
            )
            features['age_normalized'] = (features['age'] - features['age'].mean()) / (features['age'].std() + 1e-6)
        else:
            features['age'] = 5
            features['is_male'] = 0
            features['is_female'] = 0
            features['is_gelding'] = 0
            features['age_squared'] = 25
            features['age_optimal'] = 1
            features['age_normalized'] = 0
        
        # === FEATURES D'INTERACTION (15 features) ===
        features['odds_draw_interaction'] = features['odds_inv'] * features['draw_normalized']
        features['odds_weight_interaction'] = features['log_odds'] * features['weight_normalized']
        features['odds_age_interaction'] = features['odds_inv'] * features['age_normalized']
        features['weight_age_interaction'] = features['weight_normalized'] * features['age_normalized']
        features['form_odds_interaction'] = features['music_recent_form_3'] * features['odds_inv']
        features['form_weight_interaction'] = features['music_recent_form_3'] * features['weight_advantage']
        features['consistency_odds_interaction'] = features['music_consistency_score'] * features['odds_inv']
        features['winrate_odds_interaction'] = features['music_win_rate'] * features['odds_inv']
        features['recent_form_draw'] = features['music_recent_form_5'] * features['draw_advantage_score']
        features['age_optimal_odds'] = features['age_optimal'] * features['odds_inv']
        features['weight_form_combo'] = features['weight_advantage'] * features['music_place_rate']
        features['triple_interaction'] = features['odds_inv'] * features['music_recent_form_3'] * features['weight_advantage']
        features['experience_age_ratio'] = features['music_total_races'] / (features['age'] + 1)
        features['quality_index'] = features['music_win_rate'] * features['music_consistency_score'] * features['odds_inv']
        features['composite_performance'] = (
            features['music_recent_form_5'] * 0.3 +
            features['music_win_rate'] * 0.25 +
            features['music_place_rate'] * 0.25 +
            features['music_consistency_score'] * 0.2
        )
        
        # === FEATURES DE CONTEXTE (7 features) ===
        features['field_size'] = len(df)
        features['competitiveness_index'] = df['odds_numeric'].std() / (df['odds_numeric'].mean() + 1e-6)
        features['is_favorite'] = (df['odds_numeric'] == df['odds_numeric'].min()).astype(int)
        features['is_second_favorite'] = (df['odds_numeric'] == df['odds_numeric'].nsmallest(2).iloc[-1]).astype(int)
        features['is_outsider'] = (df['odds_numeric'] > df['odds_numeric'].quantile(0.75)).astype(int)
        features['relative_strength'] = features['odds_inv'] / features['odds_inv'].sum()
        features['market_share'] = 1 / (df['odds_numeric'] * len(df))
        
        # === FEATURES STATISTIQUES AVANC√âES (5 features) ===
        features['performance_volatility'] = features['music_position_std'] / (features['music_avg_position'] + 1)
        features['risk_adjusted_performance'] = features['music_win_rate'] / (features['music_position_std'] + 1)
        features['momentum_score'] = features['music_improvement_trend'] * features['music_recent_form_3']
        features['reliability_score'] = (1 - features['music_dns_dnf_rate']) * features['music_consistency_score']
        features['peak_performance_indicator'] = 1 / (features['music_best_position'] + 1)
        
        return features.fillna(0)

# ============================================================================
# MOD√àLE ML AVANC√â MULTI-ALGORITHMES
# ============================================================================

@st.cache_resource
class EnhancedHorseRacingML:
    """Syst√®me ML avanc√© avec multiples algorithmes et ensemble learning"""
    
    def __init__(self):
        self.models = {}
        self.ensemble = None
        self.scaler = StandardScaler()
        self.feature_importance = {}
        self.cv_scores = {}
        self.best_model_name = None
        self.is_trained = False
        
        self._initialize_models()
    
    def _initialize_models(self):
        """Initialisation de tous les mod√®les ML"""
        
        # 1. R√©gression Ridge (r√©gularisation L2)
        self.models['Ridge'] = Ridge(alpha=1.0, random_state=42)
        
        # 2. R√©gression Lasso (r√©gularisation L1, s√©lection de features)
        self.models['Lasso'] = Lasso(alpha=0.1, random_state=42, max_iter=2000)
        
        # 3. ElasticNet (combinaison L1 + L2)
        self.models['ElasticNet'] = ElasticNet(alpha=0.5, l1_ratio=0.5, random_state=42, max_iter=2000)
        
        # 4. Random Forest (ensemble de d√©cision)
        self.models['RandomForest'] = RandomForestRegressor(
            n_estimators=200,
            max_depth=10,
            min_samples_split=10,
            min_samples_leaf=4,
            max_features='sqrt',
            random_state=42,
            n_jobs=-1
        )
        
        # 5. Gradient Boosting (boosting s√©quentiel)
        self.models['GradientBoosting'] = GradientBoostingRegressor(
            n_estimators=150,
            learning_rate=0.05,
            max_depth=6,
            min_samples_split=10,
            subsample=0.8,
            random_state=42
        )
        
        # 6. R√©seau de Neurones (Deep Learning)
        self.models['NeuralNetwork'] = MLPRegressor(
            hidden_layer_sizes=(128, 64, 32, 16),
            activation='relu',
            solver='adam',
            alpha=0.001,
            batch_size=32,
            learning_rate='adaptive',
            learning_rate_init=0.001,
            max_iter=500,
            early_stopping=True,
            validation_fraction=0.2,
            random_state=42
        )
    
    def create_synthetic_targets(self, X):
        """Cr√©ation de targets synth√©tiques r√©alistes bas√©s sur les features"""
        
        # Pond√©ration bas√©e sur la logique des courses hippiques
        weights = {
            'odds_inv': 0.30,                    # Cote inverse (30%)
            'music_recent_form_3': 0.15,         # Forme r√©cente (15%)
            'music_win_rate': 0.12,              # Taux de victoire (12%)
            'music_place_rate': 0.10,            # Taux de place (10%)
            'weight_advantage': 0.08,            # Avantage de poids (8%)
            'composite_performance': 0.08,       # Performance composite (8%)
            'quality_index': 0.07,               # Index qualit√© (7%)
            'consistency_score': 0.05,           # Consistance (5%)
            'age_optimal': 0.03,                 # √Çge optimal (3%)
            'draw_advantage_score': 0.02         # Avantage position (2%)
        }
        
        y_synthetic = np.zeros(len(X))
        
        for feature, weight in weights.items():
            if feature in X.columns:
                feature_norm = (X[feature] - X[feature].min()) / (X[feature].max() - X[feature].min() + 1e-6)
                y_synthetic += feature_norm * weight
        
        # Ajout de bruit r√©aliste (¬± 5%)
        noise = np.random.normal(0, 0.05, len(X))
        y_synthetic += noise
        
        # Normalisation finale
        y_synthetic = (y_synthetic - y_synthetic.min()) / (y_synthetic.max() - y_synthetic.min() + 1e-6)
        
        return y_synthetic
    
    def train_with_cross_validation(self, X, y, cv_folds=5):
        """Entra√Ænement avec validation crois√©e pour tous les mod√®les"""
        
        kf = KFold(n_splits=cv_folds, shuffle=True, random_state=42)
        
        for name, model in self.models.items():
            try:
                # Validation crois√©e
                scores = cross_val_score(
                    model, X, y,
                    cv=kf,
                    scoring='neg_mean_squared_error',
                    n_jobs=-1
                )
                
                # Conversion en RMSE
                rmse_scores = np.sqrt(-scores)
                
                # Calcul du R¬≤
                r2_scores = cross_val_score(model, X, y, cv=kf, scoring='r2', n_jobs=-1)
                
                self.cv_scores[name] = {
                    'rmse_mean': rmse_scores.mean(),
                    'rmse_std': rmse_scores.std(),
                    'r2_mean': r2_scores.mean(),
                    'r2_std': r2_scores.std(),
                    'scores': rmse_scores
                }
                
            except Exception as e:
                st.warning(f"‚ö†Ô∏è Erreur CV pour {name}: {str(e)}")
                self.cv_scores[name] = {
                    'rmse_mean': 999,
                    'rmse_std': 0,
                    'r2_mean': 0,
                    'r2_std': 0,
                    'scores': [999]
                }
    
    def train_all_models(self, X, y):
        """Entra√Ænement de tous les mod√®les"""
        
        predictions_dict = {}
        
        for name, model in self.models.items():
            try:
                model.fit(X, y)
                pred = model.predict(X)
                predictions_dict[name] = pred
                
                # Extraction de l'importance des features
                if hasattr(model, 'feature_importances_'):
                    importance = dict(zip(X.columns, model.feature_importances_))
                    top_features = dict(sorted(importance.items(), key=lambda x: x[1], reverse=True)[:15])
                    self.feature_importance[name] = top_features
                
                elif hasattr(model, 'coef_'):
                    importance = dict(zip(X.columns, np.abs(model.coef_)))
                    top_features = dict(sorted(importance.items(), key=lambda x: x[1], reverse=True)[:15])
                    self.feature_importance[name] = top_features
                
            except Exception as e:
                st.warning(f"‚ö†Ô∏è Erreur entra√Ænement {name}: {str(e)}")
                predictions_dict[name] = np.zeros(len(X))
        
        return predictions_dict
    
    def create_ensemble_predictions(self, predictions_dict, cv_scores):
        """Cr√©ation de pr√©dictions d'ensemble pond√©r√©es par performance"""
        
        # Pond√©ration bas√©e sur les scores de validation crois√©e
        weights = {}
        total_r2 = sum(score['r2_mean'] for score in cv_scores.values() if score['r2_mean'] > 0)
        
        if total_r2 > 0:
            for name, score in cv_scores.items():
                if score['r2_mean'] > 0:
                    weights[name] = score['r2_mean'] / total_r2
                else:
                    weights[name] = 0
        else:
            # Pond√©ration uniforme si pas de bons scores
            weights = {name: 1/len(predictions_dict) for name in predictions_dict}
        
        # Calcul de la pr√©diction d'ensemble
        ensemble_pred = np.zeros(len(list(predictions_dict.values())[0]))
        
        for name, pred in predictions_dict.items():
            ensemble_pred += pred * weights.get(name, 0)
        
        # D√©termination du meilleur mod√®le
        best_model = max(cv_scores.items(), key=lambda x: x[1]['r2_mean'])
        self.best_model_name = best_model[0]
        
        return ensemble_pred, weights
    
    def calculate_prediction_confidence(self, predictions_dict, X):
        """Calcul de la confiance dans les pr√©dictions"""
        
        # Variance entre les pr√©dictions des diff√©rents mod√®les
        all_preds = np.array(list(predictions_dict.values()))
        pred_variance = np.var(all_preds, axis=0)
        
        # Confiance inversement proportionnelle √† la variance
        confidence_base = 1 / (1 + pred_variance * 10)
        
        # Ajustement par la qualit√© des features
        feature_quality = 1 - (X.isna().sum(axis=1) / len(X.columns))
        
        # Confiance finale
        confidence = confidence_base * feature_quality.values
        confidence = np.clip(confidence, 0.2, 1.0)  # Entre 20% et 100%
        
        return confidence
    
    def fit_predict(self, X_raw, race_type="PLAT"):
        """Pipeline complet : entra√Ænement et pr√©diction"""
        
        if len(X_raw) < 5:
            st.error("‚ö†Ô∏è Minimum 5 chevaux requis pour l'analyse ML")
            return np.zeros(len(X_raw)), {}, np.ones(len(X_raw)) * 0.5
        
        # Normalisation des features
        X_scaled = pd.DataFrame(
            self.scaler.fit_transform(X_raw),
            columns=X_raw.columns,
            index=X_raw.index
        )
        
        # Cr√©ation des targets synth√©tiques
        y_synthetic = self.create_synthetic_targets(X_raw)
        
        # Validation crois√©e
        with st.spinner("üî¨ Validation crois√©e en cours..."):
            self.train_with_cross_validation(X_scaled, y_synthetic)
        
        # Entra√Ænement de tous les mod√®les
        with st.spinner("ü§ñ Entra√Ænement des mod√®les ML..."):
            predictions_dict = self.train_all_models(X_scaled, y_synthetic)
        
        # Cr√©ation de l'ensemble
        ensemble_predictions, model_weights = self.create_ensemble_predictions(
            predictions_dict, self.cv_scores
        )
        
        # Calcul de la confiance
        confidence = self.calculate_prediction_confidence(predictions_dict, X_raw)
        
        self.is_trained = True
        
        return ensemble_predictions, self.cv_scores, confidence

# ============================================================================
# FONCTIONS UTILITAIRES
# ============================================================================

@st.cache_data(ttl=300)
def scrape_race_data(url):
    """Web scraping des donn√©es de course"""
    try:
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}
        response = requests.get(url, headers=headers, timeout=10)
        
        if response.status_code != 200:
            return None, f"Erreur HTTP {response.status_code}"

        soup = BeautifulSoup(response.content, 'html.parser')
        horses_data = []
        
        table = soup.find('table')
        if not table:
            return None, "Aucun tableau trouv√©"
            
        rows = table.find_all('tr')[1:]
        
        for row in rows:
            cols = row.find_all(['td', 'th'])
            if len(cols) >= 4:
                horses_data.append({
                    "Num√©ro de corde": cols[0].get_text(strip=True),
                    "Nom": cols[1].get_text(strip=True),
                    "Cote": cols[-1].get_text(strip=True),
                    "Poids": cols[-2].get_text(strip=True) if len(cols) > 4 else "60.0",
                    "Musique": cols[2].get_text(strip=True) if len(cols) > 5 else "",
                    "√Çge/Sexe": cols[3].get_text(strip=True) if len(cols) > 6 else "",
                })

        if not horses_data:
            return None, "Aucune donn√©e extraite"
            
        return pd.DataFrame(horses_data), "Succ√®s"
        
    except Exception as e:
        return None, f"Erreur: {str(e)}"

def safe_convert(value, convert_func, default=0):
    """Conversion s√©curis√©e avec gestion d'erreurs"""
    try:
        if pd.isna(value):
            return default
        cleaned = str(value).replace(',', '.').strip()
        return convert_func(cleaned)
    except:
        return default

def prepare_data(df):
    """Pr√©paration et nettoyage des donn√©es"""
    df = df.copy()
    df['odds_numeric'] = df['Cote'].apply(lambda x: safe_convert(x, float, 999))
    df['draw_numeric'] = df['Num√©ro de corde'].apply(lambda x: safe_convert(x, int, 1))
    
    def extract_weight(poids_str):
        if pd.isna(poids_str):
            return 60.0
        match = re.search(r'(\d+(?:[.,]\d+)?)', str(poids_str))
        return float(match.group(1).replace(',', '.')) if match else 60.0
    
    df['weight_kg'] = df['Poids'].apply(extract_weight)
    df = df[df['odds_numeric'] > 0]
    df = df.reset_index(drop=True)
    return df

def auto_detect_race_type(df):
    """D√©tection automatique du type de course"""
    weight_std = df['weight_kg'].std()
    weight_mean = df['weight_kg'].mean()
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("üí™ √âcart-type poids", f"{weight_std:.1f} kg")
    with col2:
        st.metric("‚öñÔ∏è Poids moyen", f"{weight_mean:.1f} kg")
    with col3:
        st.metric("üèá Nb chevaux", len(df))
    
    if weight_std > 2.5:
        detected = "PLAT"
        reason = "Grande variation de poids (handicap)"
    elif weight_mean > 65 and weight_std < 1.5:
        detected = "ATTELE_AUTO"
        reason = "Poids uniformes √©lev√©s (attel√©)"
    else:
        detected = "PLAT"
        reason = "Configuration par d√©faut"
    
    st.info(f"ü§ñ **Type d√©tect√©**: {detected} | **Raison**: {reason}")
    return detected

def generate_combinations(df_ranked, combination_type="quinte"):
    """G√©n√©ration de combinaisons gagnantes"""
    top_horses = df_ranked.head(10)
    
    if combination_type == "quinte":
        # Top 5 avec confiance
        top_5 = top_horses.head(5)
        return {
            'type': 'Quint√©+ Ordre',
            'selection': list(top_5['Nom']),
            'numeros': list(top_5['Num√©ro de corde']),
            'confidence_avg': top_5['confidence'].mean()
        }
    
    elif combination_type == "trio":
        # Top 3
        top_3 = top_horses.head(3)
        return {
            'type': 'e-Trio',
            'selection': list(top_3['Nom']),
            'numeros': list(top_3['Num√©ro de corde']),
            'confidence_avg': top_3['confidence'].mean()
        }
    
    elif combination_type == "super4":
        # Top 4
        top_4 = top_horses.head(4)
        return {
            'type': 'e-Super4',
            'selection': list(top_4['Nom']),
            'numeros': list(top_4['Num√©ro de corde']),
            'confidence_avg': top_4['confidence'].mean()
        }

def create_advanced_visualizations(df_ranked, ml_model):
    """Visualisations compl√®tes des r√©sultats ML"""
    
    fig = make_subplots(
        rows=3, cols=3,
        subplot_titles=(
            'üèÜ Scores de Pr√©diction',
            'üìä Distribution Cotes',
            'üß† Importance Features (RF)',
            '‚öñÔ∏è Poids vs Performance',
            'üìà Performances CV',
            'üéØ Corr√©lation Cotes-Scores',
            'üî• Forme R√©cente Top 10',
            'üìâ Variance Pr√©dictions',
            'üé≤ Analyse de Confiance'
        ),
        specs=[
            [{"secondary_y": False}, {"type": "histogram"}, {"type": "bar"}],
            [{"type": "scatter"}, {"type": "bar"}, {"type": "scatter"}],
            [{"type": "bar"}, {"type": "box"}, {"type": "scatter"}]
        ]
    )
    
    colors = px.colors.qualitative.Set3
    
    # 1. Scores avec confiance
    fig.add_trace(
        go.Scatter(
            x=df_ranked['rang'],
            y=df_ranked['score_final'],
            mode='markers+lines',
            marker=dict(
                size=df_ranked['confidence'] * 25,
                color=df_ranked['confidence'],
                colorscale='Viridis',
                showscale=True,
                colorbar=dict(title="Confiance", x=0.35)
            ),
            text=df_ranked['Nom'],
            hovertemplate='<b>%{text}</b><br>Score: %{y:.3f}<br>Rang: %{x}',
            name='Score ML'
        ), row=1, col=1
    )
    
    # 2. Distribution des cotes
    fig.add_trace(
        go.Histogram(
            x=df_ranked['odds_numeric'],
            nbinsx=15,
            marker_color=colors[1],
            name='Distribution'
        ), row=1, col=2
    )
    
    # 3. Importance des features (Random Forest)
    if ml_model.feature_importance and 'RandomForest' in ml_model.feature_importance:
        importance = ml_model.feature_importance['RandomForest']
        top_10 = dict(list(importance.items())[:10])
        fig.add_trace(
            go.Bar(
                x=list(top_10.values()),
                y=list(top_10.keys()),
                orientation='h',
                marker_color=colors[2],
                name='Importance'
            ), row=1, col=3
        )
    
    # 4. Poids vs Performance
    fig.add_trace(
        go.Scatter(
            x=df_ranked['weight_kg'],
            y=df_ranked['score_final'],
            mode='markers',
            marker=dict(
                size=12,
                color=df_ranked['rang'],
                colorscale='RdYlGn_r',
                showscale=False,
                line=dict(width=1, color='white')
            ),
            text=df_ranked['Nom'],
            hovertemplate='<b>%{text}</b><br>Poids: %{x} kg<br>Score: %{y:.3f}',
            name='Poids-Score'
        ), row=2, col=1
    )
    
    # 5. Performances de validation crois√©e
    if ml_model.cv_scores:
        models = list(ml_model.cv_scores.keys())
        r2_means = [ml_model.cv_scores[m]['r2_mean'] for m in models]
        r2_stds = [ml_model.cv_scores[m]['r2_std'] for m in models]
        
        fig.add_trace(
            go.Bar(
                x=models,
                y=r2_means,
                error_y=dict(type='data', array=r2_stds),
                marker_color=colors[4],
                name='R¬≤ Score'
            ), row=2, col=2
        )
    
    # 6. Corr√©lation Cotes-Scores
    fig.add_trace(
        go.Scatter(
            x=df_ranked['odds_numeric'],
            y=df_ranked['score_final'],
            mode='markers',
            marker=dict(
                size=10,
                color=colors[5],
                line=dict(width=1, color='white')
            ),
            text=df_ranked['Nom'],
            hovertemplate='<b>%{text}</b><br>Cote: %{x}<br>Score: %{y:.3f}',
            name='Corr√©lation'
        ), row=2, col=3
    )
    
    # 7. Forme r√©cente Top 10
    top_10 = df_ranked.head(10)
    fig.add_trace(
        go.Bar(
            x=top_10['Nom'],
            y=top_10['music_recent_form_3'],
            marker_color=colors[6],
            name='Forme r√©cente'
        ), row=3, col=1
    )
    
    # 8. Variance des pr√©dictions (boxplot)
    fig.add_trace(
        go.Box(
            y=df_ranked['score_final'],
            marker_color=colors[7],
            name='Distribution scores'
        ), row=3, col=2
    )
    
    # 9. Analyse de confiance
    fig.add_trace(
        go.Scatter(
            x=df_ranked['odds_numeric'],
            y=df_ranked['confidence'],
            mode='markers',
            marker=dict(
                size=10,
                color=df_ranked['score_final'],
                colorscale='Plasma',
                showscale=False,
                line=dict(width=1, color='white')
            ),
            text=df_ranked['Nom'],
            hovertemplate='<b>%{text}</b><br>Cote: %{x}<br>Confiance: %{y:.1%}',
            name='Confiance'
        ), row=3, col=3
    )
    
    fig.update_layout(
        height=1000,
        showlegend=False,
        title_text="üìä Dashboard Complet d'Analyse ML",
        title_x=0.5,
        title_font_size=22
    )
    
    return fig

def create_performance_report(df_ranked, ml_model, race_type):
    """G√©n√©ration d'un rapport d√©taill√© de performance"""
    
    report = f"""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë           RAPPORT D'ANALYSE HIPPIQUE ML AVANC√â               ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

üìÖ Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
üèÅ Type de course: {race_type}
üèá Nombre de partants: {len(df_ranked)}

‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                    TOP 5 PR√âDICTIONS ML                       ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

"""
    
    for i in range(min(5, len(df_ranked))):
        horse = df_ranked.iloc[i]
        confidence_emoji = "üü¢" if horse['confidence'] >= 0.7 else "üü°" if horse['confidence'] >= 0.4 else "üî¥"
        
        report += f"""
{i+1}. {horse['Nom'].upper()}
   ‚îú‚îÄ üìä Cote: {horse['Cote']} | Num√©ro: {horse['Num√©ro de corde']}
   ‚îú‚îÄ üéØ Score ML: {horse['score_final']:.4f}
   ‚îú‚îÄ {confidence_emoji} Confiance: {horse['confidence']:.1%}
   ‚îú‚îÄ ‚öñÔ∏è Poids: {horse['weight_kg']} kg
   ‚îú‚îÄ üèÜ Victoires: {horse.get('music_wins', 'N/A')}
   ‚îú‚îÄ üìà Forme r√©cente: {horse.get('music_recent_form_3', 0):.3f}
   ‚îî‚îÄ üé≤ Taux de victoire: {horse.get('music_win_rate', 0):.1%}
"""
    
    if ml_model.cv_scores:
        report += f"""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë              PERFORMANCES DES MOD√àLES ML                      ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

"""
        for model_name, scores in ml_model.cv_scores.items():
            report += f"""
{model_name}:
   ‚îú‚îÄ R¬≤ Score: {scores['r2_mean']:.4f} (¬± {scores['r2_std']:.4f})
   ‚îú‚îÄ RMSE: {scores['rmse_mean']:.4f} (¬± {scores['rmse_std']:.4f})
   ‚îî‚îÄ √âvaluation: {"Excellent" if scores['r2_mean'] > 0.8 else "Bon" if scores['r2_mean'] > 0.6 else "Mod√©r√©"}
"""
    
    if ml_model.best_model_name:
        report += f"""
üèÜ Meilleur mod√®le: {ml_model.best_model_name}

"""
    
    # Statistiques globales
    avg_confidence = df_ranked['confidence'].mean()
    high_confidence = len(df_ranked[df_ranked['confidence'] >= 0.7])
    
    report += f"""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                  STATISTIQUES GLOBALES                        ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

‚îú‚îÄ üéØ Confiance moyenne: {avg_confidence:.1%}
‚îú‚îÄ üü¢ Pr√©dictions haute confiance (‚â•70%): {high_confidence}
‚îú‚îÄ ‚≠ê Favoris (cote < 5): {len(df_ranked[df_ranked['odds_numeric'] < 5])}
‚îú‚îÄ üé≤ Outsiders (cote > 15): {len(df_ranked[df_ranked['odds_numeric'] > 15])}
‚îî‚îÄ üìä Indice de comp√©titivit√©: {df_ranked['odds_numeric'].std() / df_ranked['odds_numeric'].mean():.3f}

‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                  RECOMMANDATIONS STRAT√âGIQUES                 ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

"""
    
    # Chevaux √† fort potentiel (bon score, cote int√©ressante, haute confiance)
    value_horses = df_ranked[
        (df_ranked['score_final'] > df_ranked['score_final'].quantile(0.6)) &
        (df_ranked['odds_numeric'] > 5) &
        (df_ranked['confidence'] > 0.5)
    ].head(3)
    
    if len(value_horses) > 0:
        report += "üíé CHEVAUX √Ä VALEUR:\n"
        for idx, horse in value_horses.iterrows():
            report += f"   ‚úì {horse['Nom']} - Cote: {horse['Cote']} | Score: {horse['score_final']:.3f}\n"
    
    # Alertes
    weak_favorites = df_ranked[
        (df_ranked['odds_numeric'] < 5) &
        (df_ranked['score_final'] < df_ranked['score_final'].median())
    ]
    
    if len(weak_favorites) > 0:
        report += f"\n‚ö†Ô∏è ALERTES: {len(weak_favorites)} favori(s) avec score ML faible\n"
    
    report += "\n" + "‚ïê" * 67 + "\n"
    report += "Note: Ce rapport est bas√© sur une analyse ML pr√©dictive.\n"
    report += "Les courses hippiques comportent toujours une part d'al√©atoire.\n"
    report += "‚ïê" * 67 + "\n"
    
    return report

def generate_test_data(data_type="plat"):
    """G√©n√©ration de donn√©es de test r√©alistes"""
    if data_type == "plat":
        return pd.DataFrame({
            'Nom': ['Golden Flash', 'Silver Storm', 'Bronze King', 'Diamond Star', 
                    'Emerald Wave', 'Ruby Fire', 'Sapphire Sky', 'Pearl Ocean'],
            'Num√©ro de corde': ['1', '2', '3', '4', '5', '6', '7', '8'],
            'Cote': ['3.5', '5.2', '8.1', '6.8', '11.5', '15.2', '22.0', '18.5'],
            'Poids': ['56.0', '57.5', '58.0', '59.5', '57.0', '60.5', '62.0', '61.0'],
            'Musique': ['1a1a2a1a3a', '2a3a1a2a4a', '1a4a3a2a1a', '3a1a5a2a3a',
                        '5a4a2a6a3a', '4a6a5a8a7a', '7a8a9a6a5a', '6a5a7a4a8a'],
            '√Çge/Sexe': ['4H', '5M', '3F', '6H', '4M', '5H', '7M', '4F']
        })
    elif data_type == "attele":
        return pd.DataFrame({
            'Nom': ['Thunder Bolt', 'Lightning Fast', 'Storm Chaser', 'Wind Runner',
                    'Rain Maker', 'Cloud Dancer'],
            'Num√©ro de corde': ['1', '2', '3', '4', '5', '6'],
            'Cote': ['4.8', '7.2', '3.5', '9.5', '12.0', '16.5'],
            'Poids': ['68.0', '68.0', '68.0', '68.0', '68.0', '68.0'],
            'Musique': ['1a2a1a3a1a', '3a4a2a1a5a', '1a1a2a1a3a', '4a5a3a6a2a',
                        '6a4a7a5a8a', '8a7a6a9a4a'],
            '√Çge/Sexe': ['5H', '6M', '4F', '7H', '5M', '6H']
        })

# ============================================================================
# APPLICATION PRINCIPALE
# ============================================================================

def main():
    st.markdown('<h1 class="main-header">üèá Analyseur Hippique Pro ML v2.0</h1>', unsafe_allow_html=True)
    st.markdown("**Syst√®me d'analyse pr√©dictive avanc√© avec Machine Learning multi-algorithmes**")
    st.markdown("*R√©gression, Deep Learning & Ensemble Methods*")
    
    # === SIDEBAR CONFIGURATION ===
    with st.sidebar:
        st.header("‚öôÔ∏è Configuration ML")
        
        race_type_selection = st.selectbox(
            "üèÅ Type de course",
            ["AUTO", "PLAT", "ATTELE_AUTO", "ATTELE_VOLTE", "OBSTACLE"]
        )
        
        use_ml = st.checkbox("‚úÖ Activer ML Avanc√©", value=True)
        
        if use_ml:
            ml_weight = st.slider(
                "üéØ Pond√©ration ML vs Cotes",
                0.0, 1.0, 0.75, 0.05,
                help="0 = uniquement cotes, 1 = uniquement ML"
            )
        else:
            ml_weight = 0.0
        
        st.markdown("---")
        st.subheader("ü§ñ Mod√®les Utilis√©s")
        st.info("‚úÖ Ridge Regression")
        st.info("‚úÖ Lasso Regression")
        st.info("‚úÖ ElasticNet")
        st.info("‚úÖ Random Forest (200 arbres)")
        st.info("‚úÖ Gradient Boosting")
        st.info("‚úÖ Neural Network (4 couches)")
        
        st.markdown("---")
        st.subheader("üìä Features G√©n√©r√©es")
        st.success("**79 features** cr√©√©es automatiquement:")
        st.caption("‚Ä¢ 8 features de cote")
        st.caption("‚Ä¢ 6 features de position")
        st.caption("‚Ä¢ 8 features de poids")
        st.caption("‚Ä¢ 20 features de musique")
        st.caption("‚Ä¢ 7 features √¢ge/sexe")
        st.caption("‚Ä¢ 15 features d'interaction")
        st.caption("‚Ä¢ 7 features de contexte")
        st.caption("‚Ä¢ 5 features statistiques")
        
        st.markdown("---")
        st.subheader("‚ÑπÔ∏è Informations")
        st.info("üî¨ **M√©thode**: Validation crois√©e 5-fold")
        st.info("üéØ **Objectif**: Pr√©dire la performance relative")
        st.info("üìà **Optimisation**: Ensemble learning")
    
    # === ONGLETS PRINCIPAUX ===
    tab1, tab2, tab3 = st.tabs(["üåê Analyse URL", "üìÅ Upload CSV", "üß™ Donn√©es Test"])
    
    df_final = None
    
    with tab1:
        st.subheader("üîç Analyse d'URL de Course")
        col1, col2 = st.columns([4, 1])
        with col1:
            url = st.text_input(
                "üåê URL de la course:",
                placeholder="https://www.geny.fr/courses-pmu/..."
            )
        with col2:
            st.markdown("<br>", unsafe_allow_html=True)
            analyze_btn = st.button("üîç Analyser", type="primary", use_container_width=True)
        
        if analyze_btn and url:
            with st.spinner("üîÑ Extraction des donn√©es..."):
                df, message = scrape_race_data(url)
                if df is not None:
                    st.success(f"‚úÖ {len(df)} chevaux extraits")
                    st.dataframe(df, use_container_width=True)
                    df_final = df
                else:
                    st.error(f"‚ùå {message}")
    
    with tab2:
        st.subheader("üì§ Upload de fichier CSV")
        st.markdown("**Format requis**: `Nom, Num√©ro de corde, Cote, Poids, Musique, √Çge/Sexe`")
        
        uploaded_file = st.file_uploader("Choisir un fichier CSV", type="csv")
        if uploaded_file:
            try:
                df_final = pd.read_csv(uploaded_file)
                st.success(f"‚úÖ {len(df_final)} chevaux charg√©s")
                st.dataframe(df_final, use_container_width=True)
            except Exception as e:
                st.error(f"‚ùå Erreur: {e}")
    
    with tab3:
        st.subheader("üß™ Donn√©es de Test")
        
        col1, col2 = st.columns(2)
        with col1:
            if st.button("üèÉ Test Course de PLAT", use_container_width=True):
                df_final = generate_test_data("plat")
                st.success("‚úÖ 8 chevaux charg√©s (Course de PLAT)")
        with col2:
            if st.button("üöó Test Course ATTEL√â", use_container_width=True):
                df_final = generate_test_data("attele")
                st.success("‚úÖ 6 chevaux charg√©s (Trot Attel√©)")
        
        if df_final is not None:
            st.dataframe(df_final, use_container_width=True)
    
    # === ANALYSE PRINCIPALE ===
    if df_final is not None and len(df_final) > 0:
        st.markdown("---")
        st.header("üéØ Analyse ML et Pr√©dictions")
        
        # Pr√©paration des donn√©es
        df_prepared = prepare_data(df_final)
        
        if len(df_prepared) == 0:
            st.error("‚ùå Aucune donn√©e valide")
            return
        
        # D√©tection du type de course
        if race_type_selection == "AUTO":
            detected_type = auto_detect_race_type(df_prepared)
        else:
            detected_type = race_type_selection
            config_desc = RACE_CONFIGS.get(detected_type, {}).get('description', 'Configuration personnalis√©e')
            st.info(f"üìã **Type s√©lectionn√©**: {detected_type}")
        
        # === EXTRACTION DES FEATURES ===
        with st.spinner("üî¨ Extraction des features avanc√©es..."):
            X_features = AdvancedFeatureExtractor.create_comprehensive_features(
                df_prepared,
                detected_type
            )
            df_prepared = pd.concat([df_prepared, X_features], axis=1)
        
        st.success(f"‚úÖ **{len(X_features.columns)} features** cr√©√©es avec succ√®s")
        
        # === MACHINE LEARNING ===
        ml_model = EnhancedHorseRacingML()
        
        if use_ml:
            # Entra√Ænement ML
            ml_predictions, cv_scores, confidence = ml_model.fit_predict(
                X_features,
                detected_type
            )
            
            # Normalisation
            if ml_predictions.max() != ml_predictions.min():
                ml_predictions_norm = (ml_predictions - ml_predictions.min()) / \
                                     (ml_predictions.max() - ml_predictions.min())
            else:
                ml_predictions_norm = ml_predictions
            
            df_prepared['ml_score'] = ml_predictions_norm
            df_prepared['confidence'] = confidence
            
            # Affichage des performances ML
            st.markdown("### üìä Performances des Mod√®les ML")
            
            cols = st.columns(len(cv_scores))
            for idx, (model_name, scores) in enumerate(cv_scores.items()):
                with cols[idx]:
                    st.metric(
                        model_name,
                        f"R¬≤: {scores['r2_mean']:.3f}",
                        f"¬±{scores['r2_std']:.3f}",
                        delta_color="normal"
                    )
        
        # === SCORE TRADITIONNEL (BAS√â SUR LES COTES) ===
        traditional_score = 1 / (df_prepared['odds_numeric'] + 0.1)
        if traditional_score.max() != traditional_score.min():
            traditional_score = (traditional_score - traditional_score.min()) / \
                              (traditional_score.max() - traditional_score.min())
        
        # === SCORE FINAL (HYBRIDE) ===
        if use_ml and 'ml_score' in df_prepared.columns:
            df_prepared['score_final'] = (
                (1 - ml_weight) * traditional_score +
                ml_weight * df_prepared['ml_score']
            )
        else:
            df_prepared['score_final'] = traditional_score
            df_prepared['confidence'] = np.ones(len(df_prepared)) * 0.5
        
        # === CLASSEMENT ===
        df_ranked = df_prepared.sort_values('score_final', ascending=False).reset_index(drop=True)
        df_ranked['rang'] = range(1, len(df_ranked) + 1)
        
        # === AFFICHAGE DES R√âSULTATS ===
        st.markdown("---")
        st.header("üèÜ Classement Final & Pronostics")
        
        col1, col2 = st.columns([2.5, 1.5])
        
        with col1:
            st.subheader("üìã Classement Complet")
            
            # Pr√©paration affichage
            display_df = df_ranked[[
                'rang', 'Nom', 'Num√©ro de corde', 'Cote',
                'weight_kg', 'score_final', 'confidence'
            ]].copy()
            
            display_df.columns = [
                'Rang', 'Nom', 'N¬∞', 'Cote',
                'Poids (kg)', 'Score ML', 'Confiance'
            ]
            
            display_df['Score ML'] = display_df['Score ML'].apply(lambda x: f"{x:.4f}")
            display_df['Confiance'] = display_df['Confiance'].apply(lambda x: f"{x:.1%}")
            display_df['Poids (kg)'] = display_df['Poids (kg)'].apply(lambda x: f"{x:.1f}")
            
            st.dataframe(
                display_df,
                use_container_width=True,
                height=500
            )
        
        with col2:
            st.subheader("üéØ Top 5 D√©taill√©")
            
            for i in range(min(5, len(df_ranked))):
                horse = df_ranked.iloc[i]
                conf = horse['confidence']
                
                if conf >= 0.7:
                    conf_class = "confidence-high"
                    conf_emoji = "üü¢"
                elif conf >= 0.4:
                    conf_class = "confidence-medium"
                    conf_emoji = "üü°"
                else:
                    conf_class = "confidence-low"
                    conf_emoji = "üî¥"
                
                st.markdown(f"""
                <div class="prediction-box">
                    <strong style="font-size: 1.1em;">{i+1}. {horse['Nom']}</strong><br>
                    üìä Cote: <strong>{horse['Cote']}</strong> | 
                    üî¢ N¬∞: <strong>{horse['Num√©ro de corde']}</strong><br>
                    üéØ Score ML: <strong>{horse['score_final']:.4f}</strong><br>
                    {conf_emoji} Confiance: <span class="{conf_class}">{conf:.1%}</span><br>
                    ‚öñÔ∏è Poids: {horse['weight_kg']:.1f} kg<br>
                    üèÜ Victoires: {horse.get('music_wins', 0)} | 
                    üìà Forme: {horse.get('music_recent_form_3', 0):.2f}
                </div>
                """, unsafe_allow_html=True)
            
            # M√©triques globales
            st.markdown("### üìä Statistiques")
            avg_conf = df_ranked['confidence'].mean()
            st.metric("Confiance Moyenne", f"{avg_conf:.1%}")
            
            high_conf = len(df_ranked[df_ranked['confidence'] >= 0.7])
            st.metric("Haute Confiance (‚â•70%)", high_conf)
            
            favorites = len(df_ranked[df_ranked['odds_numeric'] < 5])
            st.metric("Favoris (cote < 5)", favorites)
        
        # === COMBINAISONS GAGNANTES ===
        st.markdown("---")
        st.subheader("üé≤ Combinaisons Recommand√©es")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            quinte = generate_combinations(df_ranked, "quinte")
            st.markdown("**üèÜ Quint√©+ Ordre**")
            st.info(f"Confiance: {quinte['confidence_avg']:.1%}")
            for i, (name, num) in enumerate(zip(quinte['selection'], quinte['numeros']), 1):
                st.write(f"{i}. **{name}** (N¬∞{num})")
        
        with col2:
            trio = generate_combinations(df_ranked, "trio")
            st.markdown("**ü•â e-Trio**")
            st.info(f"Confiance: {trio['confidence_avg']:.1%}")
            for i, (name, num) in enumerate(zip(trio['selection'], trio['numeros']), 1):
                st.write(f"{i}. **{name}** (N¬∞{num})")
        
        with col3:
            super4 = generate_combinations(df_ranked, "super4")
            st.markdown("**‚≠ê e-Super4**")
            st.info(f"Confiance: {super4['confidence_avg']:.1%}")
            for i, (name, num) in enumerate(zip(super4['selection'], super4['numeros']), 1):
                st.write(f"{i}. **{name}** (N¬∞{num})")
        
        # === VISUALISATIONS AVANC√âES ===
        st.markdown("---")
        st.header("üìä Visualisations et Analytics")
        
        if use_ml:
            fig = create_advanced_visualizations(df_ranked, ml_model)
            st.plotly_chart(fig, use_container_width=True)
        
        # === ANALYSE DES FEATURES ===
        if use_ml and ml_model.feature_importance:
            st.markdown("---")
            st.header("üî¨ Analyse de l'Importance des Features")
            
            tab_rf, tab_gb, tab_nn = st.tabs([
                "üå≤ Random Forest",
                "üìà Gradient Boosting",
                "üß† Comparaison"
            ])
            
            with tab_rf:
                if 'RandomForest' in ml_model.feature_importance:
                    st.markdown("**Top 15 Features - Random Forest**")
                    importance_df = pd.DataFrame(
                        list(ml_model.feature_importance['RandomForest'].items()),
                        columns=['Feature', 'Importance']
                    ).sort_values('Importance', ascending=False)
                    
                    fig_rf = px.bar(
                        importance_df,
                        x='Importance',
                        y='Feature',
                        orientation='h',
                        title='Importance des Features (Random Forest)',
                        color='Importance',
                        color_continuous_scale='Viridis'
                    )
                    st.plotly_chart(fig_rf, use_container_width=True)
                    
                    st.dataframe(importance_df, use_container_width=True, height=400)
            
            with tab_gb:
                if 'GradientBoosting' in ml_model.feature_importance:
                    st.markdown("**Top 15 Features - Gradient Boosting**")
                    importance_df = pd.DataFrame(
                        list(ml_model.feature_importance['GradientBoosting'].items()),
                        columns=['Feature', 'Importance']
                    ).sort_values('Importance', ascending=False)
                    
                    fig_gb = px.bar(
                        importance_df,
                        x='Importance',
                        y='Feature',
                        orientation='h',
                        title='Importance des Features (Gradient Boosting)',
                        color='Importance',
                        color_continuous_scale='Plasma'
                    )
                    st.plotly_chart(fig_gb, use_container_width=True)
                    
                    st.dataframe(importance_df, use_container_width=True, height=400)
            
            with tab_nn:
                st.markdown("**üìä Comparaison des Mod√®les**")
                
                if ml_model.cv_scores:
                    comparison_data = []
                    for model_name, scores in ml_model.cv_scores.items():
                        comparison_data.append({
                            'Mod√®le': model_name,
                            'R¬≤ Moyen': scores['r2_mean'],
                            'R¬≤ Std': scores['r2_std'],
                            'RMSE Moyen': scores['rmse_mean'],
                            'RMSE Std': scores['rmse_std']
                        })
                    
                    comparison_df = pd.DataFrame(comparison_data)
                    comparison_df = comparison_df.sort_values('R¬≤ Moyen', ascending=False)
                    
                    st.dataframe(
                        comparison_df.style.format({
                            'R¬≤ Moyen': '{:.4f}',
                            'R¬≤ Std': '{:.4f}',
                            'RMSE Moyen': '{:.4f}',
                            'RMSE Std': '{:.4f}'
                        }),
                        use_container_width=True
                    )
                    
                    # Graphique de comparaison
                    fig_comp = go.Figure()
                    
                    fig_comp.add_trace(go.Bar(
                        name='R¬≤ Score',
                        x=comparison_df['Mod√®le'],
                        y=comparison_df['R¬≤ Moyen'],
                        error_y=dict(type='data', array=comparison_df['R¬≤ Std']),
                        marker_color='lightblue'
                    ))
                    
                    fig_comp.update_layout(
                        title='Comparaison des Performances (R¬≤ Score)',
                        xaxis_title='Mod√®le',
                        yaxis_title='R¬≤ Score',
                        height=400
                    )
                    
                    st.plotly_chart(fig_comp, use_container_width=True)
                    
                    if ml_model.best_model_name:
                        st.success(f"üèÜ **Meilleur mod√®le**: {ml_model.best_model_name}")
        
        # === RECOMMANDATIONS STRAT√âGIQUES ===
        st.markdown("---")
        st.header("üí° Recommandations Strat√©giques")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### üíé Chevaux √† Forte Valeur")
            st.caption("Score √©lev√© + Cote int√©ressante + Haute confiance")
            
            value_horses = df_ranked[
                (df_ranked['score_final'] > df_ranked['score_final'].quantile(0.6)) &
                (df_ranked['odds_numeric'] > 5) &
                (df_ranked['confidence'] > 0.5)
            ].head(5)
            
            if len(value_horses) > 0:
                for idx, horse in value_horses.iterrows():
                    value_score = horse['score_final'] * horse['confidence'] * (1/horse['odds_numeric'])
                    st.success(
                        f"‚úÖ **{horse['Nom']}** (N¬∞{horse['Num√©ro de corde']}) - "
                        f"Cote: {horse['Cote']} | Score: {horse['score_final']:.3f} | "
                        f"Confiance: {horse['confidence']:.1%}"
                    )
            else:
                st.info("Aucun outsider √† fort potentiel d√©tect√©")
        
        with col2:
            st.markdown("#### ‚ö†Ô∏è Alertes et Observations")
            
            # Favoris sous-performants
            weak_favorites = df_ranked[
                (df_ranked['odds_numeric'] < 5) &
                (df_ranked['score_final'] < df_ranked['score_final'].median())
            ]
            
            if len(weak_favorites) > 0:
                st.warning(
                    f"‚ö†Ô∏è **{len(weak_favorites)} favori(s) avec score ML faible**\n\n" +
                    "\n".join([f"‚Ä¢ {h['Nom']} (cote {h['Cote']})" for _, h in weak_favorites.iterrows()])
                )
            
            # Surprises potentielles
            surprise_horses = df_ranked[
                (df_ranked['odds_numeric'] > 10) &
                (df_ranked['rang'] <= 5)
            ]
            
            if len(surprise_horses) > 0:
                st.info(
                    f"üé≤ **{len(surprise_horses)} outsider(s) dans le Top 5 !**\n\n" +
                    "\n".join([f"‚Ä¢ {h['Nom']} (cote {h['Cote']}, rang {h['rang']})" 
                              for _, h in surprise_horses.iterrows()])
                )
            
            # Coh√©rence g√©n√©rale
            top3_avg_odds = df_ranked.head(3)['odds_numeric'].mean()
            if top3_avg_odds < 7:
                st.success("‚úÖ Classement coh√©rent avec le march√©")
            else:
                st.warning("üéØ Classement ML diverge du march√©")
        
        # === ANALYSE DE LA FORME ===
        st.markdown("---")
        st.header("üìà Analyse de la Forme R√©cente")
        
        top_10_form = df_ranked.head(10)
        
        fig_form = go.Figure()
        
        fig_form.add_trace(go.Bar(
            name='Forme 3 courses',
            x=top_10_form['Nom'],
            y=top_10_form['music_recent_form_3'],
            marker_color='lightblue'
        ))
        
        fig_form.add_trace(go.Bar(
            name='Forme 5 courses',
            x=top_10_form['Nom'],
            y=top_10_form['music_recent_form_5'],
            marker_color='lightcoral'
        ))
        
        fig_form.update_layout(
            title='Forme R√©cente - Top 10',
            xaxis_title='Cheval',
            yaxis_title='Score de Forme',
            barmode='group',
            height=400
        )
        
        st.plotly_chart(fig_form, use_container_width=True)
        
        # === EXPORT DES R√âSULTATS ===
        st.markdown("---")
        st.header("üíæ Export et Rapports")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            # Export CSV
            csv_export = df_ranked[[
                'rang', 'Nom', 'Num√©ro de corde', 'Cote', 'weight_kg',
                'score_final', 'confidence', 'music_wins', 'music_win_rate',
                'music_recent_form_3', 'music_recent_form_5'
            ]].copy()
            
            csv_data = csv_export.to_csv(index=False)
            st.download_button(
                "üìÑ T√©l√©charger CSV Complet",
                csv_data,
                f"pronostics_ml_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                "text/csv",
                use_container_width=True
            )
        
        with col2:
            # Export JSON
            json_export = df_ranked[[
                'rang', 'Nom', 'Num√©ro de corde', 'Cote',
                'score_final', 'confidence'
            ]].to_dict('records')
            
            json_data = json.dumps(json_export, indent=2, ensure_ascii=False)
            st.download_button(
                "üìã T√©l√©charger JSON",
                json_data,
                f"pronostics_ml_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                "application/json",
                use_container_width=True
            )
        
        with col3:
            # Rapport complet
            report = create_performance_report(df_ranked, ml_model, detected_type)
            st.download_button(
                "üìä T√©l√©charger Rapport Complet",
                report,
                f"rapport_ml_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                "text/plain",
                use_container_width=True
            )
        
        # === SECTION EXPLICATIVE ===
        st.markdown("---")
        with st.expander("üìö **Comprendre l'Analyse ML**"):
            st.markdown("""
            ### üéØ M√©thodologie
            
            Notre syst√®me utilise une approche **multi-mod√®les** avec 6 algorithmes diff√©rents :
            
            1. **Ridge Regression** : R√©gression lin√©aire avec r√©gularisation L2
            2. **Lasso Regression** : R√©gression avec s√©lection automatique de features (L1)
            3. **ElasticNet** : Combinaison de Ridge et Lasso
            4. **Random Forest** : Ensemble de 200 arbres de d√©cision
            5. **Gradient Boosting** : Boosting s√©quentiel pour am√©lioration progressive
            6. **Neural Network** : R√©seau de neurones profond (4 couches : 128‚Üí64‚Üí32‚Üí16)
            
            ### üìä Features Utilis√©es (79 au total)
            
            **Cotes (8 features)** : Cote brute, inverse, log, racine carr√©e, rang, percentile, z-score
            
            **Position (6 features)** : Num√©ro de corde, avantage position, distance optimale
            
            **Poids (8 features)** : Poids brut, normalis√©, rang, avantage, classification
            
            **Musique (20 features)** : Victoires, places, taux de r√©ussite, forme r√©cente (3/5/10 courses),
            consistance, tendance d'am√©lioration, s√©ries de victoires
            
            **√Çge/Sexe (7 features)** : √Çge, sexe, cat√©gorie d'√¢ge, √¢ge optimal
            
            **Interactions (15 features)** : Combinaisons entre cotes, poids, √¢ge, forme
            
            **Contexte (7 features)** : Taille du peloton, comp√©titivit√©, statut (favori/outsider)
            
            **Statistiques (5 features)** : Volatilit√©, performance ajust√©e au risque, momentum
            
            ### üî¨ Validation
            
            - **Cross-validation 5-fold** : Le mod√®le est test√© sur 5 sous-ensembles diff√©rents
            - **M√©triques R¬≤** : Mesure la qualit√© de pr√©diction (0 √† 1, 1 = parfait)
            - **RMSE** : Erreur quadratique moyenne
            - **Ensemble Learning** : Combinaison pond√©r√©e des 6 mod√®les
            
            ### üé≤ Interpr√©tation des R√©sultats
            
            - **Score ML** : Entre 0 et 1, plus √©lev√© = meilleur potentiel
            - **Confiance** : Fiabilit√© de la pr√©diction (üü¢ ‚â•70%, üü° 40-70%, üî¥ <40%)
            - **Combinaisons** : Bas√©es sur les chevaux les mieux class√©s avec haute confiance
            
            ### ‚ö†Ô∏è Avertissement
            
            Ce syst√®me est un **outil d'aide √† la d√©cision** bas√© sur des donn√©es statistiques.
            Les courses hippiques comportent toujours une part d'al√©atoire importante.
            Utilisez ces pr√©dictions comme un guide, pas comme une garantie.
            """)
        
        with st.expander("üîß **D√©tails Techniques**"):
            st.markdown(f"""
            ### üìà Performances du Syst√®me
            
            **Nombre de features** : {len(X_features.columns)}
            
            **Nombre de chevaux analys√©s** : {len(df_ranked)}
            
            **Type de course** : {detected_type}
            
            **Pond√©ration ML** : {ml_weight:.0%}
            
            ### ü§ñ Configuration des Mod√®les
            
            - Random Forest : 200 estimateurs, profondeur max 10
            - Gradient Boosting : 150 estimateurs, learning rate 0.05
            - Neural Network : Architecture [128, 64, 32, 16]
            - Validation : K-Fold avec k=5
            - Scaling : StandardScaler
            
            ### üìä Statistiques de Course
            
            - Cote moyenne : {df_ranked['odds_numeric'].mean():.2f}
            - Cote min/max : {df_ranked['odds_numeric'].min():.1f} / {df_ranked['odds_numeric'].max():.1f}
            - Poids moyen : {df_ranked['weight_kg'].mean():.1f} kg
            - Confiance moyenne : {df_ranked['confidence'].mean():.1%}
            """)

if __name__ == "__main__":
    main()
